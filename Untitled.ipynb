{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/donghyunjang/anaconda3/lib/python3.7/site-packages/jpype/_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/donghyunjang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/donghyunjang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/donghyunjang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/donghyunjang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/donghyunjang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/donghyunjang/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/donghyunjang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "# train_data = pd.read_csv(\"./train_dataset_1007.csv\")\n",
    "test_data = pd.read_csv(\"./test_dataset_1007.csv\")\n",
    "\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']\n",
    "\n",
    "\n",
    "\n",
    "# X_train = []\n",
    "# for sentence in train_data['title']:\n",
    "#     temp_X = []\n",
    "#     temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "#     temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "#     X_train.append(temp_X)\n",
    "\n",
    "X_test = []\n",
    "for sentence in test_data['title']:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(temp_X)\n",
    "\n",
    "max_words = 35000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_len = 20 # 전체 데이터의 길이를 20로 맞춘다\n",
    "\n",
    "# X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for i in range(len(test_data['label'])):\n",
    "    if test_data['label'].iloc[i] == 1:\n",
    "        y_test.append([0, 0, 1])\n",
    "    elif test_data['label'].iloc[i] == 0:\n",
    "        y_test.append([0, 1, 0])\n",
    "    elif test_data['label'].iloc[i] == -1:\n",
    "        y_test.append([1, 0, 0])\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = load_model(\"./myclassifier1.h5\")\n",
    "\n",
    "mypredict = model.predict(X_test)\n",
    "predict_labels = np.argmax(mypredict, axis=1)\n",
    "original_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(predict_labels)\n",
    "print(original_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
